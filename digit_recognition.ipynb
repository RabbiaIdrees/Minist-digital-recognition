{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcmgkt1LmOf-",
        "outputId": "8f916bb2-44df-4e37-d34d-161212c377f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Removed zipfile import as it's no longer needed\n",
        "# import zipfile\n",
        "\n",
        "# Removed unzip commands as data will be loaded directly\n",
        "# !unzip -o /mnt/data/train.csv.zip -d /content/\n",
        "# !unzip -o /mnt/data/test.csv.zip -d /content/\n",
        "\n",
        "# Use the built-in MNIST dataset from Keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize and reshape (784 → 28x28x1)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# Display shapes to confirm data is loaded correctly\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_7NOjNLp1YZ",
        "outputId": "cf2e93c3-5726-436e-d061-c0119c507362"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79FR0jQ6p5Ok",
        "outputId": "dae8267e-40c4-4e21-8c9a-ccc3c0496e6c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 24ms/step - accuracy: 0.8928 - loss: 0.3424 - val_accuracy: 0.9855 - val_loss: 0.0538\n",
            "Epoch 2/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 26ms/step - accuracy: 0.9847 - loss: 0.0488 - val_accuracy: 0.9880 - val_loss: 0.0411\n",
            "Epoch 3/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 24ms/step - accuracy: 0.9903 - loss: 0.0308 - val_accuracy: 0.9905 - val_loss: 0.0357\n",
            "Epoch 4/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9931 - loss: 0.0222 - val_accuracy: 0.9897 - val_loss: 0.0388\n",
            "Epoch 5/5\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 24ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.9905 - val_loss: 0.0369\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78162d56e290>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Save model\n",
        "model.save(\"cnn_mnist_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ai0z7j0brq38",
        "outputId": "27d00060-b7e8-4b51-8910-f7a1fbfc1da2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0399\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.12%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "T1_cgvwBr5AO",
        "outputId": "46783644-85ad-49de-c328-2e7959e79fc3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6f57003-2aa3-424e-ae1a-b24ea6e17783\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6f57003-2aa3-424e-ae1a-b24ea6e17783\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving images.png to images (1).png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "def predict_custom_image(image_path):\n",
        "    # Read and preprocess image\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    if img is None:\n",
        "        print(\"Error: Image not loaded properly.\")\n",
        "        return\n",
        "\n",
        "    img = cv2.resize(img, (28, 28))\n",
        "    img = cv2.bitwise_not(img)  # Invert to match MNIST black background\n",
        "    img = img / 255.0\n",
        "    img = img.reshape(1, 28, 28, 1)\n",
        "\n",
        "    # Load model\n",
        "    model = tf.keras.models.load_model(\"cnn_mnist_model.h5\")\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict(img)\n",
        "    predicted_digit = np.argmax(prediction)\n",
        "\n",
        "    # Show image and prediction\n",
        "    plt.imshow(img.reshape(28, 28), cmap='gray')\n",
        "    plt.title(f\"Predicted Digit: {predicted_digit}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Model Prediction: {predicted_digit}\")\n",
        "\n",
        "# Use this only AFTER you upload the image\n",
        "predict_custom_image(\"my_digit.png\")  # ← change filename if needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "AMx9D-lWtNqr",
        "outputId": "a1c03019-f204-482f-931b-bfa5cefb8235"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Prediction: 4\n"
          ]
        }
      ]
    }
  ]
}